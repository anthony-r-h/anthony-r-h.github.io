---
layout: post
title: "From Zero To Mini Homelab"
subtitle: "" 
optimized_image: /files/Homelab/Intro.jpg
category: Technology
tags:
  - Network
  - Self Hosted
  - Edcuation
  - Plan

---

<h2>Table Of Contents</h2>
<p style="margin-bottom:10px;"></p>

* toc
{:toc}

# General

## Project Goals
This home lab project is designed to be a **practical**, **efficient**, and **educational** setup for learning, experimenting, and self-hosting services. The key goals include:

- **Networking Knowledge:** Understanding how networking components interact, including VLANs, firewalls, routing, and security.
- **Virtualization & Containers:** Setting up and managing virtual machines (VMs) and containerized workloads using platforms like **Proxmox**, **Docker**, or **Portainer**.
- **Low Cost & Maintenance:** Achieving a reliable setup with minimal energy consumption, noise, and upkeep.
- **Practical & Usable:** The final solution must be **functional for daily use**, not just an experimental project.
- **Self-Hosting for Independence:** Reducing reliance on cloud services by hosting key services like **Home Assistant**, **backup solutions**, and **media streaming** in-house.

## Why a Home Lab?

A home lab provides an **isolated environment** to experiment with **enterprise-grade technologies** at home. 



# Requirements

This project must balance several factors to be **functional, reliable, and maintainable**:

1. **Physical Constraints**  
   - Must fit within a **4U, 10-inch mini rack**.
   - Components should be **efficiently arranged** for airflow and accessibility.

2. **Power Efficiency**  
   - Preference for **low-power devices** such as Intel **N100-class** processors.
   - **Passive cooling** where possible to reduce noise and energy waste.

3. **Network Performance**  
   - **2.5GbE minimum**, with potential expansion to **10GbE** if needed.
   - Consideration of **VLAN segmentation** for improved security and traffic management.

4. **Aesthetics & Clean Design**  
   - A well-organized setup with **minimal cable clutter**.
   - **Efficient power delivery** to avoid multiple bulky adapters.

5. **Scalability & Extensibility**  
   - Ability to **add more storage, network interfaces, or compute power** over time.
   - Modular approach to hardware selection.

Another factor is **cost**.



# Software & Services

##  Rationalizing Bare Metal vs Virtualized Deployments

While it is certainly possible to run everything in a virtualized environment, certain services are better suited for bare metal deployment.

- **Bare Metal:** Services that require **low latency, direct hardware access, or high availability** are best run on dedicated hardware. This includes networking components like routers, NAS systems, and DNS servers that must always be available.

- **Virtualized:** Services that benefit from **scalability, snapshots, portability, and resource sharing** are ideal for virtualization. These include applications like media servers, password managers, and smart home hubs that can be easily moved or backed up.

Another consideration is security and isolation. Services run on bare metal are not at risk of virtualization vulnerabilities. A compromised hypervisor could potentially expose VMs.

## Software & Services

| Service Type       | Software Options         | Deployment Method |
|--------------------|--------------------------|-------------------|
| DNS Sinkhole      | Pi-hole, Technitium DNS   | Bare Metal        |
| Router           | pfSense, OPNsense          | Bare Metal        |
| NAS              | TrueNAS (x86), OMV (ARM)   | Bare Metal        |
| Media Server     | Jellyfin                   | Virtualized       |
| Mobile Backup    | TBD                        | Virtualized       |
| Password Manager | Bitwarden                  | Virtualized       |
| Smart Home       | Home Assistant, Frigate    | Virtualized       |
| VPN              | WireGuard                  | Virtualized       |

# Form Factor

## Mini Rack T0

- 1U spacing is 
  - 44.45mm (1.75 inch) high
  - 220mm (8.75 inch) horizontal clearance
- Rack depth is 200mm (7.87 inch) deep, this is not strict, since you _can_ have devices hanging off the back
- Total height of 4U of space is available

## Additional Considerations
- **Cooling:** Passive cooling is preferred, but forced airflow may be necessary for high-power devices.
- **Cable Management:** The use of **short, right-angle cables** and proper routing will keep the setup clean and organized.
- **Power Supply Strategy:** A mix of **DC-powered devices** and **rack-mounted power solutions** will minimize bulky adapters.

## Layout

### LabStack Mini 2U Bracket

https://github.com/JaredC01/LabStack/tree/main

- Each slot is 50x71mm
- A double-width module has **105mm** horizontal clearance
- Possibility of a 2.5-width module?


SendCutSend tips

```
Measurement Units: mm (millimeter)
Material Type: 5052 H32 Aluminum
Material Thickness: 0.125" (3.2mm)
```

#### Useful LabStack Rack

- 1U Mini 2x Keystone + 2x SMA module
  - https://github.com/JaredC01/LabStack/blob/main/LabStack%20Mini/STLs/1U%20Mini%202x%20Keystone%202x%20SMA%20Left%20Mount.stl
  - https://github.com/JaredC01/LabStack/blob/main/LabStack%20Mini/STLs/1U%20Mini%202x%20Keystone%202x%20SMA%20Right%20Mount.stl
- 1U Blank 
  - https://github.com/JaredC01/LabStack/blob/main/LabStack%20Mini/STLs/1U%20Mini%20Blank%20Panel.stl
- 2U 2x80mm fan pannel
  - https://github.com/JaredC01/LabStack/blob/main/LabStack%20Mini/STLs/2U%20Mini%202x%2080mm%20Fan%20Panel.stl

#### Useful LabStack Modules

- Radxa X4 w/ POE and Heatsink
  - https://github.com/JaredC01/LabStack/blob/main/Modules/STLs/Module%201x%20Radxa%20X4%20with%20PoE%20and%20Heatsink.stl
- Pi w/ Hat
  - https://github.com/JaredC01/LabStack/blob/main/Modules/STLs/Module%201x%20Pi%20with%20HAT.stl
- Pi w/ SSD
  - https://github.com/JaredC01/LabStack/blob/main/Modules/STLs/Module%201x%20Pi%20with%2025%20SSD.stl
- 4x Keystone
  - https://github.com/JaredC01/LabStack/blob/main/Modules/STLs/Module%204x%20Keystone.stl
- Blank
  - https://github.com/JaredC01/LabStack/blob/main/Modules/STLs/Module%20Blank.stl
- 3x 2.5" SSD
  - https://github.com/JaredC01/LabStack/blob/main/Modules/STLs/Module%203x%2025%20SSD.stl




### Front
```
+----------------------------------+
| 1U | [ Switch ]                  |
|----------------------------------|
| 2U | [ Patch Panel ] [ Proxmox ] |
|    | [ Pi-like Devices ]         |
|----------------------------------|
| 1U | [ NAS ]                     |
+----------------------------------+
```

TODO: clarify device sizes.

### Back

```
+----------------------------------+
| 1U | [ Router ]                  | 
|----------------------------------|
| 1U | [ Open ]                    | 
|----------------------------------|
| 1U | [ Power Distribution (PDU)] | 
|----------------------------------|
| 1U | [ Open ]                    | 
+----------------------------------+

```

# Devices

## Switch

### Notes

- Needs to be 1U
- 2.5G + SPF
- POE
- Ideally, powered from the back side

### Options

- TEG-3102WS

## DNS sinkhole

### Notes

- Can be virtualized, but want to run it _bare metal_

### Options

- Pi 4
  - 1GbE, ~4W-5W idle
  - Overkill
- ZimbaBoard 232
  - Overkill

## Router

### Notes

- For OpnSense
- 2.5Gbps

### Options

- Protectli
  - expensive
- QOTOM Q730G5*
  - 155x127*48mm -> Needs 2U
- Mikrotik 5009, 4011 or 2004
- Banana Pi R4
  - Way too experimental for my taste

## Hypervisor

### Notes

Needs

- Intel VT-x, VT-d for virtualization and passthrough
- 2.5GbE
- 32GB RAM
- USB ports
- IPMI/iKVM are nice to have, but not available for consumer devices

Accelerator

- NVIDIA Jetson
- Coral

### Devices

- Radxa X4
  - N100
  - Fits LabStack Mini
  - A lot of Pi hats wont work because this is x86
- Radxa (Palmshell)
  - SLiM X4L
- Minix Z100
  - Passive
  - N100
  - NVME and has a Wifi card which can swap for storage
  - 120x123x46mm - won't fit LabStack doulbe-width module
- UP 4000/ 7000/ 710S ...
- MeLE Quieter4C
  - Passive
  - N100, and other options
  - 13x18x8cm - fits


## NAS 

### Notes

TrueNAS requires x86 hardware and does not support ARM. For ARM devices, OMV seems to be the only option. While there are very compelling ARM options, for example (FriendlyElec CM3588), OMV seems lackluster and considerably less mature.

So we're going x86. First a few points

1. CPU

| Processor Model | TDP (Watts) | PCI Express Lanes |
|-----------------|-------------|-------------------|
| Intel N100      | 6 W         | 9                 |
| Intel N125      | 6 W         | 9                 |
| Intel N355      | 15 W        | 9                 |
| Core i3-12100T  | 35 W        | 20                |
| Core i3-12300T  | 35 W        | 20                |

2. PCI-Express Lanes

- 10GbE takes 4 lanes
- 2.5GbE takes 1 lane
- SATA RAID controller 4 lanes
- PCIe x1 RAID card uses one lane, PCIe x4 RAID card uses four lanes
- NVMe drives, like 980 Pro use x4 lanes
    - A lot of boards use bifurcation, so NVMe drives each run x1
- N100 and related SoC boards which support 4x NVMe drives are limited by PCI-E lanes and run at 1x

On a typical N100-class board the lanes are deployed as follows

| Component                        | PCIe Lanes Used |
|----------------------------------|----------------|
| M.2 NVMe SSD                     | 4 lanes        |
| 2.5GbE Network Interface (NIC)    | 1 lane         |
| Mini PCIe Slot (WiFi, LTE, etc.)  | 1 lane         |
| SATA Controller (PCIe to SATA)    | 2 lanes        |
| USB Controller (High-speed USB)   | 1 lane         |
| **Total**                         | **9 lanes**    |

3. PCI Express Bandwidth

| PCIe Version | Lanes | Bandwidth (Gbps) | Bandwidth (GBps) |
|-------------|------|-----------------|-----------------|
| PCIe 3.0   | x1   | 8 Gbps          | 1 GBps         |
| PCIe 3.0   | x4   | 32 Gbps         | 4 GBps         |
| PCIe 3.0   | x8   | 64 Gbps         | 8 GBps         |
| PCIe 3.0   | x16  | 128 Gbps        | 16 GBps        |
| PCIe 4.0   | x1   | 16 Gbps         | 2 GBps         |
| PCIe 4.0   | x4   | 64 Gbps         | 8 GBps         |
| PCIe 4.0   | x8   | 128 Gbps        | 16 GBps        |
| PCIe 4.0   | x16  | 256 Gbps        | 32 GBps        |

Also SATA III has about ~750 MB/s bandwidth.

4. Network Bandwidth

| Ethernet Standard | Bandwidth (Gbps) | Bandwidth (GBps) |
|------------------|-----------------|-----------------|
| 1GbE            | 1 Gbps           | 0.125 GBps      |
| 2.5GbE          | 2.5 Gbps         | 0.3125 GBps     |
| 10GbE           | 10 Gbps          | 1.25 GBps       |

So on a 2.5GbE NIC, M2 drives running PCIe 3.0 x1 will be limitted by the network interface.

Running interface bonding/aggregation with two 2.5GbE ports would double the bandwidth, but still be the bottleneck.

5. Creative Things

- M2 to occulink
- M2 to PCI Express
- M2 to SATA
  - JMB575 (port multiplier) doesn't support ASPM which prevents motherboard from going into lower power state
  - ASM1164, ASM1166 are better

#### A full mini-ITX device

Pros:

- Most flexibility
- No option to run embedded/mobile CPUs like the N100, so PCIe lane limitation is not an issue
- Access to a full sized PCI-Express slot
  - There are boards with integrated 2.5 Gbps NICs
  - So PCI-Express x16 slot can be used for M2 array, or SATA controller
- Standard power options: Flex ATX, pico

Cons:

- At a minimum, will occupy 2U of space due to the cooler
  - Integrated solutions (like mini-PCs or embedded boards) have proprietary, optimized cooling to reduce size
  - In addition, mounting for storage devices, power need to be solutioned
  - Currently, there is only one 10 inch rackmount mini-ITX case available. It is expensive, and not refined
- Constrained by slots and ports
  - If there isn't a 2.5GbE or 10GbE interface, a dedicated NIC will be required
  - Since there are unlikley more than one PCI-e slots, then it can't be used for anything else
  - Such as a quality SATA controller, even if the board has sufficient SATA ports
- By far, the most expensive option

There are few suitable board options currently.

#### _Vintage_ ???

- Dell Optiplex 5060, Lenovo M920, HP Prodesk 600 G4
    - How to power drives?
    - Can use raid controller card like LSI

#### SoC board

But can I trust these devices?

- Topton, CWWK _purple board_
  - Can be powered with Pico PSU
  - N100-class CPU
  - Need mounting solution for drives
- ODROID-H4 Plus
  - Same
- Radxa X4
  - Don't think they have a SATA hat
#### Mini PC

- CWWK x86-P6
  - PCIe 3.0 x1 (bifurcation)

#### Turnkey Solution

- Minisforum MS01
- Asustor Something
- TerraMaster F8






# other notes

- https://old.reddit.com/r/minilab/comments/1iblpux/10_nas_concept_hba_dock_via_oculink/
- labstack mini prints






# how dakota put 3d models?


### Interactive Model 


https://moaatt2.github.io/minima-testing/2023/01/25/chainmail-cube.html
